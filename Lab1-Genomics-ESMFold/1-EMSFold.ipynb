{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d2f9a46-e534-419e-9039-11bbcd102002",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook will introduce some base API functionality of the ESMFold LLM, which is a Metagenomics Atlas. Allowing us to Fold a protein sequence to see the resultant predicted structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71976231-c209-40a1-8e9e-1f2a088b0a43",
   "metadata": {},
   "source": [
    "We will use the following Python libraries:\n",
    "\n",
    "- PyTorch\n",
    "- esm\n",
    "- prothelpers\n",
    "- py3Dmol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8847dbb0-3660-4965-9cd3-c5b29be06c5f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a39041-cf03-4b4a-afc4-e3adafc5ba5f",
   "metadata": {},
   "source": [
    "Will walkthrough each stage step-by-step carrying out the following taks:\n",
    "\n",
    "1. Download Protein PDB data\n",
    "2. Parse the protein data\n",
    "3. Visualise protein data\n",
    "4. Extract an experimental structure and sequence of chain\n",
    "5. Setup a pre-trained ESMFold model using AutoTokenizer from HuggingFace\n",
    "6. Tokenise sequence (experimental structure from step 4.) to convert it into numerical format (so can be used by ESMFold for prediciton)\n",
    "7. Use instantiated ESMFold Model to make prediction\n",
    "8. Submit tokenised sequence to ESMFold model to make prediction of the 3D Structure (May take ~5 minutes on non hardware accelerated setup)\n",
    "9. View result visualisation\n",
    "10. Evaluate accuracy of prediction by comapring to experimental structure.\n",
    "11. Calculate TM-Score and RMSD to evaluate overall prediction experimentation\n",
    "12. Finish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd82a9e-0b9b-412e-a318-eff40d755ef1",
   "metadata": {},
   "source": [
    "### 1. Download Protein PDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fdd113-0193-4d0c-990d-81ad60687a1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPDB\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDBList, MMCIFParser\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpy3Dmol\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Bio'"
     ]
    }
   ],
   "source": [
    "from Bio.PDB import PDBList, MMCIFParser\n",
    "import os\n",
    "import py3Dmol\n",
    "from prothelpers.structure import atoms_to_pdb\n",
    "import warnings\n",
    "\n",
    "target_id = \"1N8Z\"\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "pdbl = PDBList()\n",
    "filename = pdbl.retrieve_pdb_file(target_id, pdir=\"data\", file_format=\"mmCif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98190270-efd4-495b-bf70-a4005c78bafa",
   "metadata": {},
   "source": [
    "### 2. Parse the protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c812e44-6ff6-45f1-af4e-311a753ad42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = MMCIFParser()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    structure_1N8Z = parser.get_structure(target_id, filename)\n",
    "pdb_string = atoms_to_pdb(structure_1N8Z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbe41b-a4bc-4d47-bc5a-32e1324560f7",
   "metadata": {},
   "source": [
    "### 3. Visualise protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace55e0b-3f53-4712-b02e-f4ade94add59",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = py3Dmol.view(width=600, height=400)\n",
    "view.addModel(pdb_string)\n",
    "view.setStyle({\"chain\": \"A\"}, {\"cartoon\": {\"color\": \"orange\", \"opacity\": 0.5}})\n",
    "view.setStyle({\"chain\": \"B\"}, {\"cartoon\": {\"color\": \"blue\"}})\n",
    "view.setStyle({\"chain\": \"C\"}, {\"cartoon\": {\"color\": \"green\", \"opacity\": 0.5}})\n",
    "view.zoomTo()\n",
    "view.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8196522f-ece8-49b6-a35c-877331e9d71a",
   "metadata": {},
   "source": [
    "### 4. Extract an experimental structure and sequence of chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a47af5-9e6b-44b4-97c2-91a93883fe77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prothelpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprothelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstructure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_aa_seq\n\u001b[1;32m      3\u001b[0m experimental_structure \u001b[38;5;241m=\u001b[39m atoms_to_pdb(structure_1N8Z[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/experimental.pdb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prothelpers'"
     ]
    }
   ],
   "source": [
    "from prothelpers.structure import get_aa_seq\n",
    "\n",
    "experimental_structure = atoms_to_pdb(structure_1N8Z[0][\"B\"])\n",
    "with open(\"data/experimental.pdb\", \"w\") as f:\n",
    "    f.write(experimental_structure)\n",
    "\n",
    "experimental_sequence = get_aa_seq(structure_1N8Z[0][\"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea77e7-b34b-40f9-a325-49614235d906",
   "metadata": {},
   "source": [
    "### 5. Setup a pre-trained ESMFold model using AutoTokenizer from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767d5a1-c487-4ca0-9618-41d38b2f2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, EsmForProteinFolding\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esmfold_v1\")\n",
    "model = EsmForProteinFolding.from_pretrained(\n",
    "    \"facebook/esmfold_v1\", low_cpu_mem_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205449f-8718-4a96-a301-397ab4c9b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model.esm = model.esm.float()\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "\n",
    "model = model.to(device)\n",
    "model.trunk.set_chunk_size(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2a687-2b26-4bdf-b19c-d217d819c34b",
   "metadata": {},
   "source": [
    "### 6. Tokenise sequence \n",
    "Experimental structure from step 4, to convert it into numerical format (so can be used by ESMFold for prediciton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2d64f1-e4ae-4be6-8f3b-72fcdc2ea61a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized_input \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(\n\u001b[1;32m      2\u001b[0m     [experimental_sequence], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m tokenized_input \u001b[38;5;241m=\u001b[39m tokenized_input\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe human-readable sequence is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperimental_sequence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(\n",
    "    [experimental_sequence], return_tensors=\"pt\", add_special_tokens=False\n",
    ")[\"input_ids\"]\n",
    "tokenized_input = tokenized_input.to(device)\n",
    "\n",
    "print(f\"The human-readable sequence is {experimental_sequence}\")\n",
    "print(f\"The tokenized representation of the sequences is {tokenized_input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9339bfa2-e236-4471-af69-688647e73275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
